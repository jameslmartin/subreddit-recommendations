{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import gensim\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql_conn = sqlite3.connect('../data/database.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These functions are needed for processing later\n",
    "\n",
    "# Takes a sentence in a comment and converts it to a list of words.\n",
    "def comment_to_wordlist(comment, remove_stopwords=False ):\n",
    "    comment = re.sub(\"[^a-zA-Z]\",\" \", comment)\n",
    "    words = comment.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    return(words)\n",
    "\n",
    "# Takes a comment and converts it to an array of sentences\n",
    "def comment_to_sentence(comment, tokenizer, remove_stopwords=False):\n",
    "    raw_sentences = tokenizer.tokenize(comment.strip())\n",
    "    \n",
    "    sentences = []\n",
    "    for s in raw_sentences:\n",
    "        if len(s)>0:\n",
    "            sentences.append(comment_to_wordlist(s, remove_stopwords))\n",
    "    #rof\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice of subreddits\n",
    "\n",
    "These subreddits contain discussions on 11 fairly distinct topic, from a human point of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mathematics = pd.read_sql(\"SELECT subreddit, body FROM May2015 WHERE subreddit == 'mathematics'\",sql_conn)\n",
    "\n",
    "computerscience = pd.read_sql(\"SELECT subreddit, body FROM May2015 WHERE subreddit == 'computerscience'\",sql_conn)\n",
    "\n",
    "history = pd.read_sql(\"SELECT subreddit, body FROM May2015 WHERE subreddit == 'history'\",sql_conn)\n",
    "\n",
    "philosophy = pd.read_sql(\"SELECT subreddit, body FROM May2015 WHERE subreddit == 'philosophy'\",sql_conn)\n",
    "\n",
    "elifive = pd.read_sql(\"SELECT subreddit, body FROM May2015 WHERE subreddit == 'explainlikeimfive'\",sql_conn)\n",
    "\n",
    "askanthro = pd.read_sql(\"SELECT subreddit, body FROM May2015 WHERE subreddit == 'AskAnthropology'\",sql_conn)\n",
    "\n",
    "homebrewing = pd.read_sql(\"SELECT subreddit, body FROM May2015 WHERE subreddit == 'Homebrewing'\",sql_conn)\n",
    "\n",
    "bicycling = pd.read_sql(\"SELECT subreddit, body FROM May2015 WHERE subreddit == 'bicycling'\", sql_conn)\n",
    "\n",
    "food = pd.read_sql(\"SELECT subreddit, body FROM May2015 WHERE subreddit == 'food'\", sql_conn)\n",
    "\n",
    "gaming = pd.read_sql(\"SELECT subreddit, body FROM May2015 WHERE subreddit == 'gaming'\", sql_conn)\n",
    "\n",
    "politics = pd.read_sql(\"SELECT subreddit, body FROM May2015 WHERE subreddit == 'politics'\", sql_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Array of tuples, with df and subject\n",
    "subreddits = [(bicycling,'bicycling'),(history,'history'),(philosophy,'philosophy'),\n",
    "              (elifive,'explain'),(homebrewing,'homebrew'),(askanthro,'anthropology'),\n",
    "              (mathematics,'mathematics'),(computerscience,'computer science'),\n",
    "              (food,\"food\"),(gaming,\"gaming\"),(politics,\"politics\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 999300 entries, 0 to 999299\n",
      "Data columns (total 2 columns):\n",
      "subreddit    999300 non-null object\n",
      "body         999300 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 22.9+ MB\n"
     ]
    }
   ],
   "source": [
    "all_frames = [bicycling, history, philosophy, elifive, homebrewing, askanthro, mathematics,\\\n",
    "              computerscience, food, gaming, politics]\n",
    "model_training_data = pd.concat(all_frames, ignore_index=True)\n",
    "model_training_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['300features_50minwords_10context', '300features_40minwords_3context', '300features_20minwords_3context', '300features_40minwords_5context', '300features_10minwords_3context', '300features_10minwords_5context', '300features_50minwords_5context', '300features_30minwords_5context', '300features_40minwords_10context', '300features_20minwords_5context', '300features_10minwords_10context', '300features_20minwords_10context', '300features_30minwords_3context', '300features_50minwords_3context', '300features_30minwords_10context']\n"
     ]
    }
   ],
   "source": [
    "# Get all model files\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "models = [f for f in listdir('models/') if isfile(join('models/', f)) and not f.endswith('.npy')]\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(word, label):\n",
    "    return model.similarity(word, label)\n",
    "\n",
    "def label_comment(comment, labels):\n",
    "    # Set initial distance high\n",
    "    best_distance = 1e8\n",
    "    best_label = \"\"\n",
    "    for label in labels:\n",
    "        word_dists_to_label = map(f(word,label), comment)\n",
    "        # Compute average similarity to label\n",
    "        dist = sum(word_dists_to_label)/len(word_dists_to_label)\n",
    "        if dist < best_distance:\n",
    "            best_label = label\n",
    "            best_distance = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300features_50minwords_10context\n",
      "300features_40minwords_3context\n",
      "300features_20minwords_3context\n",
      "300features_40minwords_5context\n",
      "300features_10minwords_3context\n",
      "300features_10minwords_5context\n",
      "300features_50minwords_5context\n",
      "300features_30minwords_5context\n",
      "300features_40minwords_10context\n",
      "300features_20minwords_5context\n",
      "300features_10minwords_10context\n",
      "300features_20minwords_10context\n",
      "300features_30minwords_3context\n",
      "300features_50minwords_3context\n",
      "300features_30minwords_10context\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "# Attempt to load each model\n",
    "for m in models:\n",
    "    print(m)\n",
    "    current_model = word2vec.Word2Vec.load('models/' + m);\n",
    "    \n",
    "    # Take each comment, compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'vegas', 0.707527756690979),\n",
       " (u'scrolls', 0.6396520137786865),\n",
       " (u'morrowind', 0.6132481098175049),\n",
       " (u'eso', 0.6038081645965576),\n",
       " (u'nv', 0.5972005128860474),\n",
       " (u'tes', 0.5942018032073975),\n",
       " (u'skyrim', 0.5849278569221497),\n",
       " (u'oblivion', 0.5718768835067749),\n",
       " (u'obsidian', 0.5705356597900391),\n",
       " (u'series', 0.5462707281112671)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_model.most_similar(\"fallout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
